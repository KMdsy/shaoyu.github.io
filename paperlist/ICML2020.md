# ICML 2020 (2020.07.12)
[Link](https://icml.cc/Conferences/2020/Schedule?type=Poster)

[Schedule](https://icml.cc/Conferences/2020/Schedule)

## Anomaly

+ Interpretable, Multidimensional, Multimodal Anomaly Detection with Negative Sampling for Detection of Device Failure

  John Sipple

## Sequence

+ Population-Based Black-Box Optimization for Biological Sequence Design

  Christof Angermueller · David Belanger · Andreea Gane · Zelda Mariet · David Dohan · Kevin Murphy · Lucy Colwell · D. Sculley

+ A Chance-Constrained Generative Framework for Sequence Optimization

  Xianggen Liu · Jian Peng · Qiang Liu · Sen Song

+ An EM Approach to Non-autoregressive Conditional Sequence Generation

  Zhiqing Sun · Yiming Yang

+ CAUSE: Learning Granger Causality from Event Sequences using Attribution Methods

  Wei Zhang · Thomas Panum · Somesh Jha · Prasad Chalasani · David Page

+ Imputer: Sequence Modelling via Imputation and Dynamic Programming

  William Chan · Chitwan Saharia · Geoffrey Hinton · Mohammad Norouzi · Navdeep Jaitly

+ Incremental Sampling Without Replacement for Sequence Models

  Kensen Shi · David Bieber · Charles Sutton

+ Sequence Generation with Mixed Representations

  Lijun Wu · Shufang Xie · Yingce Xia · Yang Fan · Jian-Huang Lai · Tao Qin · Tie-Yan Liu

## Time Series

+ Learning From Irregularly-Sampled Time Series: A Missing Data Perspective

  Steven Cheng-Xian Li · Benjamin M Marlin

+ Set Functions for Time Series

  Max Horn · Michael Moor · Christian Bock · Bastian Rieck · Karsten Borgwardt
  
  *所解决的问题：针对非规则采样的时间序列的分类问题，文中的大意是还可以进行其他下游任务，而非仅有分类（更换相应的loss函数即可）。Dataset: MIMIC-III Mortality Prediction, Physionet 2012 Mortality Prediction Challenge, Physionet 2019 Sepsis Early Prediction Challenge*
  
  
  *一个非常规的做法，其理论依据是differentiable set function learning, 具备可解释性是其优点，
  在具体做法方面，pipeline如下：**多维时间序列** -> **encoding** (不使用类似seq2seq的深度学习方法，而是使用一种类似频率域分解的固定encodeing方式) -> **Embedding+Aggregation+Attention** (这一步使用深度神经网络，attention为scaled dot-product attention with multiple heads) -> **classification** (神经网络)。*
  
  *在性能方面，所提出的方法分类精度并不能达到state-of-the-art，只是和baseline有竞争性，而在可解释性、内存占用、运行时间上有优异的性能。
  BTW, baseline: GRU-D, GRU-SIMPLE, IP-NETS, PHASED-LSTM, TRANSFORMER, SEFT-ATTN*

+ Spectral Subsampling MCMC for Stationary Time Series

  Robert Salomone · Matias Quiroz · Robert kohn · Mattias Villani · Minh-Ngoc Tran

## Recurrent

+ A general recurrent state space framework for modeling neural dynamics during decision-making

  David Zoltowski · Jonathan Pillow · Scott Linderman

+ Improving the Gating Mechanism of Recurrent Neural Networks

  Albert Gu · Caglar Gulcehre · Thomas Paine · Matthew Hoffman · Razvan Pascanu

+ Approximating Stacked and Bidirectional Recurrent Architectures with the Delayed Recurrent Neural Network

  Javier Turek · Shailee Jain · Vy Vo · Mihai Capotă · Alexander Huth · Theodore Willke

+ Transformation of ReLU-based recurrent neural networks from discrete-time to continuous-time

  Zahra Monfared · Daniel Durstewitz

+ Learning to Combine Top-Down and Bottom-Up Signals in Recurrent Neural Networks with Attention over Modules

  Sarthak Mittal · Alex Lamb · Anirudh Goyal · Vikram Voleti · Murray Shanahan · Guillaume Lajoie · Michael Mozer · Yoshua Bengio

+ VideoOneNet: Bidirectional Convolutional Recurrent OneNet with Trainable Data Steps for Video Processing

  Zoltán Milacski · Barnabás Póczos · Andras Lorincz

+ Frequentist Uncertainty in Recurrent Neural Networks via Blockwise Influence Functions

  Ahmed Alaa · Mihaela van der Schaar

## Interpretable

+ Multiresolution Tensor Learning for Efficient and Interpretable Spatial Analysis

  Jung Yeon Park · Kenneth Carr · Stephan Zheng · Yisong Yue · Rose Yu

+ Interpretable Off-Policy Evaluation in Reinforcement Learning by Highlighting Influential Transitions

  Omer Gottesman · Joseph Futoma · Yao Liu · Sonali Parbhoo · Leo Celi · Emma Brunskill · Finale Doshi-Velez

+ Dispersed EM-VAEs for Interpretable Text Generation

  Wenxian Shi · Hao Zhou · Ning Miao · Lei Li

+ Interpretable, Multidimensional, Multimodal Anomaly Detection with Negative Sampling for Detection of Device Failure

  John Sipple

## Autoencoder

+ Encoding Musical Style with Transformer Autoencoders

  Kristy Choi · Curtis Hawthorne · Ian Simon · Monica Dinculescu · Jesse Engel

+ Forecasting sequential data using Consistent Koopman Autoencoders

  Omri Azencot · N. Benjamin Erichson · Vanessa Lin · Michael Mahoney

+ Latent Bernoulli Autoencoder

  Jiri Fajtl · Vasileios Argyriou · Dorothy Monekosso · Paolo Remagnino

+ Perceptual Generative Autoencoders

  Zijun Zhang · Ruixiang ZHANG · Zongpeng Li · Yoshua Bengio · Liam Paull

+ Rate-distortion optimization guided autoencoder for isometric embedding in Euclidean latent space

  Keizo Kato · Jing Zhou · Tomotake Sasaki · Akira Nakagawa

+ Educating Text Autoencoders: Latent Representation Guidance via Denoising

  Tianxiao Shen · Jonas Mueller · Regina Barzilay · Tommi Jaakkola

+ Topological Autoencoders

  Michael Moor · Max Horn · Bastian Rieck · Karsten Borgwardt

+ ControlVAE: Controllable Variational Autoencoder

  Huajie Shao · Shuochao Yao · Dachun Sun · Aston Zhang · Shengzhong Liu · Dongxin Liu · Jun Wang · Tarek Abdelzaher

+ Learning Autoencoders with Relational Regularization

  Hongteng Xu · Dixin Luo · Ricardo Henao · Svati Shah · Lawrence Carin

## LSTM

+ Do RNN and LSTM have Long Memory?

  Jingyu Zhao · Feiqing Huang · Jia Lv · Yanjie Duan · Zhen Qin · Guodong Li · Guangjian Tian
